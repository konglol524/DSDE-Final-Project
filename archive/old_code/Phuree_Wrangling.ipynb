{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get(data, path, default=None):\n",
    "    for key in path:\n",
    "        if isinstance(data, dict):\n",
    "            data = data.get(key, default)\n",
    "        elif isinstance(data, list) and isinstance(key, int) and 0 <= key < len(data):\n",
    "            data = data[key]\n",
    "        else:\n",
    "            return default\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Authors' info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract author info\n",
    "data_dir = 'Project_data'\n",
    "output_file = 'authors.csv'\n",
    "\n",
    "# Use a set to track unique author IDs\n",
    "unique_authors = set()\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Write the header once\n",
    "    writer.writerow(['at_id', 'name', 'degree'])\n",
    "\n",
    "    # Walk through all subdirectories and files\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for filename in files:\n",
    "            if filename.startswith('20'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                with open(file_path, 'r') as file:\n",
    "                    print(file_path)\n",
    "                    try:\n",
    "                        data = json.load(file)\n",
    "                        # Access authors\n",
    "                        authors = data.get('abstracts-retrieval-response', {}).get('authors', {}).get('author', [])\n",
    "                        for author in authors:\n",
    "                            at_id = author.get(\"@auid\")\n",
    "                            if at_id and at_id not in unique_authors:  # Avoid duplicates\n",
    "                                name = f\"{author.get('ce:given-name', '')} {author.get('ce:surname', '')}\".strip()\n",
    "                                degree = author.get('ce:degrees', 'NA')\n",
    "                                writer.writerow([at_id, name, degree])\n",
    "                                unique_authors.add(at_id)  # Add the ID to the set\n",
    "                    except (json.JSONDecodeError, KeyError) as e:\n",
    "                        print(f\"Error processing file {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Affiliations Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract affiliation info\n",
    "data_dir = 'Sample_data'\n",
    "output_file = 'affiliations.csv'\n",
    "unique_affiliations = set()\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['af_id', 'name', 'organization', 'country', 'city'])\n",
    "    # Walk through all subdirectories and files\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for filename in files:\n",
    "            if filename.startswith('20'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                with open(file_path, 'r') as file:\n",
    "                    \n",
    "                    try:\n",
    "                        data = json.load(file)\n",
    "                        # Access authors\n",
    "                        auth_groups = data.get('abstracts-retrieval-response', {}).get('item', {}).get('bibrecord', {}).get('head', {}).get('author-group', [])\n",
    "\n",
    "                        if isinstance(auth_groups, list):\n",
    "                            for auth_group in auth_groups:\n",
    "                                affiliation = auth_group.get('affiliation', {})   \n",
    "                                af_id = affiliation.get(\"@afid\")\n",
    "                                if af_id and af_id not in unique_affiliations:  # Avoid duplicates\n",
    "                                    org_list = affiliation.get('organization', 'NA')\n",
    "                                    if isinstance(org_list, list):\n",
    "                                        organization = ', '.join([org['$'] for org in org_list])\n",
    "                                        name = org_list[-1]['$']\n",
    "                                    elif isinstance(org_list, dict):\n",
    "                                        organization = org_list.get('$', 'NA')\n",
    "                                        name = organization\n",
    "                                    else:\n",
    "                                        organization = affiliation.get('ce:text', 'NA')\n",
    "                                        name = organization\n",
    "                                    country = affiliation.get('country', 'NA')\n",
    "                                    city = affiliation.get('city', 'NA')\n",
    "                                    writer.writerow([af_id, name, organization, country, city])\n",
    "                                    unique_affiliations.add(af_id)  # Add the ID to the set\n",
    "                        else:\n",
    "                            affiliation = auth_groups.get('affiliation', {}) \n",
    "                            af_id = affiliation.get(\"@afid\")\n",
    "                            if af_id and af_id not in unique_affiliations:  # Avoid duplicates\n",
    "                                org_list = affiliation.get('organization', 'NA')\n",
    "                                if isinstance(org_list, list):\n",
    "                                    organization = ', '.join([org['$'] for org in org_list])\n",
    "                                    name = org_list[-1]['$']\n",
    "                                elif isinstance(org_list, dict):\n",
    "                                    organization = org_list.get('$', 'NA')\n",
    "                                    name = organization\n",
    "                                else:\n",
    "                                    organization = affiliation.get('ce:text', 'NA')\n",
    "                                    name = organization\n",
    "                            country = affiliation.get('country', 'NA')\n",
    "                            city = affiliation.get('city', 'NA')\n",
    "                            writer.writerow([af_id, name, organization, country, city])\n",
    "                            unique_affiliations.add(af_id)  # Add the ID to the set\n",
    "                    except (json.JSONDecodeError, KeyError) as e:\n",
    "                        print(f\"Error processing file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author to Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Project_data'\n",
    "output_file = 'author_to_affi.csv'\n",
    "columns = ['pid', 'at_id', 'af_id']\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "    writer.writeheader()\n",
    "    # Walk through all subdirectories and files\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for filename in files:\n",
    "            if filename.startswith('20'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                with open(file_path, 'r') as file:\n",
    "                    \n",
    "                    try:\n",
    "                        data = json.load(file)\n",
    "                        auth_groups = safe_get(data, ['abstracts-retrieval-response', 'item', 'bibrecord', 'head', 'author-group'], None)\n",
    "                        if isinstance(auth_groups, list):\n",
    "                            for auth_group in auth_groups:\n",
    "                                affiliation = auth_group.get('affiliation', {})   \n",
    "                                af_id = affiliation.get(\"@afid\")\n",
    "                                authors = auth_group.get('author', [])\n",
    "                                for author in authors:\n",
    "                                    at_id = author.get('@auid')\n",
    "                                    writer.writerow({'pid': filename, 'at_id': at_id, 'af_id': af_id})\n",
    "                        else:\n",
    "                            affiliation = auth_groups.get('affiliation', {})\n",
    "                            af_id = affiliation.get(\"@afid\")\n",
    "                            authors = auth_groups.get('author', [])\n",
    "                            for author in authors:\n",
    "                                at_id = author.get('@auid')\n",
    "                                writer.writerow({'pid': filename, 'at_id': at_id, 'af_id': af_id})\n",
    "                    except Exception as e:\n",
    "                            print(f\"Error processing file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract subject area data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Project_data'\n",
    "output_file = 'subject_areas.csv'\n",
    "\n",
    "columns = [\n",
    "    'subject_area_id', 'subject_area_name',\n",
    "]\n",
    "\n",
    "unique_subject = set()\n",
    "\n",
    "\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "    writer.writeheader()\n",
    "    # Walk through all subdirectories and files\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for filename in files:\n",
    "            if filename.startswith('20'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    try:\n",
    "                        data = json.load(file)\n",
    "                        subject_areas_list = safe_get(data, ['abstracts-retrieval-response', 'subject-areas', 'subject-area'], None)\n",
    "                        for subject in subject_areas_list:\n",
    "                            subject_id = subject.get('@code', None)\n",
    "                            subject_name = subject.get('$', None)\n",
    "                            if subject_id not in unique_subject:\n",
    "                                writer.writerow({\n",
    "                                    'subject_area_id': subject_id,\n",
    "                                    'subject_area_name': subject_name\n",
    "                                })\n",
    "                                unique_subject.add(subject_id)\n",
    "                    except Exception as e:\n",
    "                            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Paper Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_codes(classification_list):\n",
    "    \"\"\"\n",
    "    Processes the classification list and extracts the relevant classification code.\n",
    "    \n",
    "    :param classification_list: List of classifications, can be of different types.\n",
    "    :return: List of classification codes.\n",
    "    \"\"\"\n",
    "    classification_codes = []\n",
    "    \n",
    "    for classification in classification_list:\n",
    "        if isinstance(classification, dict):\n",
    "            classification_type = classification.get('@type')\n",
    "            classification_data = classification.get('classification')\n",
    "            \n",
    "            if classification_type == 'SUBJABBR' or classification_type == 'ASJC':\n",
    "                # For SUBJABBR and AJSC, classification might be a single string or a list\n",
    "                if isinstance(classification_data, list):\n",
    "                    classification_codes.extend([item.get('$') for item in classification_data if isinstance(item, dict)])\n",
    "                else:\n",
    "                    classification_codes.append(classification_data)  # Single string classification\n",
    "            \n",
    "            elif classification_type in ['CPXCLASS', 'FLXCLASS']:\n",
    "                if isinstance(classification_data, list):\n",
    "                    classification_codes.extend([item.get('classification-code') for item in classification_data if isinstance(item, dict)])\n",
    "                elif isinstance(classification_data, dict):\n",
    "                    classification_codes.append(classification_data.get('classification-code'))\n",
    "    \n",
    "    return classification_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_slice_or_single(data):\n",
    "    #Ensures that the returned data is always a list, even if it's a single item.\n",
    "    if data is None:\n",
    "        return None\n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "    return [data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleidx(idxterms_data):\n",
    "    if idxterms_data:\n",
    "        if isinstance(idxterms_data, dict):  # If idxterms is a dictionary\n",
    "            mainterm = idxterms_data.get('mainterm')\n",
    "            if isinstance(mainterm, list):\n",
    "                idxterms = [i.get('$', None) for i in mainterm]  # Extract the '$' value from each item in the list\n",
    "            elif isinstance(mainterm, dict):\n",
    "                idxterms = [mainterm.get('$', None)]  # If 'mainterm' is a single dict, extract the '$'\n",
    "            else:\n",
    "                idxterms = None\n",
    "        elif isinstance(idxterms_data, list):  # If idxterms is a list\n",
    "            idxterms = [i.get('$', None) for i in idxterms_data if isinstance(i, dict)]  # Loop through and extract '$'\n",
    "        else:\n",
    "            idxterms = None\n",
    "    else:\n",
    "        idxterms = None\n",
    "    return idxterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './Sample_data'\n",
    "output_file = 'papers.csv'\n",
    "\n",
    "columns = [\n",
    "    'pid','title', 'pub_date', 'abstract', 'language', 'ref_count',\n",
    "    'citedby_count', 'corresponding_author', 'author_id', 'subject_areas_id', 'keywords',\n",
    "    'idxterms', 'classification_code'\n",
    "]\n",
    "cnt = 0\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "    writer.writeheader()\n",
    "    # Walk through all subdirectories and files\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for filename in files:\n",
    "            if cnt == 40: break\n",
    "            cnt+=1\n",
    "            if filename.startswith('20'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    try:\n",
    "                        data = json.load(file)\n",
    "                        title = safe_get(data, ['abstracts-retrieval-response', 'item', 'bibrecord', 'head', 'citation-title'], None)\n",
    "                        pub_year = safe_get(data, ['abstracts-retrieval-response', 'item', 'bibrecord', 'head', 'source', 'publicationdate', 'year'], None)\n",
    "                        pub_month = safe_get(data, ['abstracts-retrieval-response', 'item', 'bibrecord', 'head', 'source', 'publicationdate', 'month'], None)\n",
    "                        pub_day = safe_get(data, ['abstracts-retrieval-response', 'item', 'bibrecord', 'head', 'source', 'publicationdate', 'day'], None)\n",
    "                        pub_date = f\"{pub_day}/{pub_month}/{pub_year}\" if pub_year and pub_month and pub_day else None\n",
    "                        abstract = safe_get(data, ['abstracts-retrieval-response', 'item', 'bibrecord', 'head', 'abstracts'], None)\n",
    "                        language = safe_get(data, ['abstracts-retrieval-response', 'item', 'bibrecord', 'head', 'citation-info', 'citation-language', '@language'], None)\n",
    "                        ref_count = safe_get(data, ['abstracts-retrieval-response', 'item', 'bibrecord', 'tail', 'bibliography', '@refcount'], None)\n",
    "                        citedby_count = safe_get(data, ['abstracts-retrieval-response', 'coredata', 'citedby-count'], None)\n",
    "                        \n",
    "                        \n",
    "                        authors_list = safe_get(data, ['abstracts-retrieval-response', 'authors', 'author'], None)\n",
    "                        author_dict= {f\"{author.get('ce:given-name', '')} {author.get('ce:surname', '')}\".strip() : author.get('@auid', None) for author in authors_list if isinstance(author, dict)} if authors_list else None\n",
    "                        author_id = list(author_dict.values())\n",
    "                        cor_author = safe_get(data, ['abstracts-retrieval-response', 'item', 'bibrecord', 'head', 'correspondence', 'person'], None)\n",
    "                        ca_name = f\"{safe_get(cor_author, ['ce:given-name'], '')} {safe_get(cor_author, ['ce:surname'], '')}\".strip()\n",
    "                        \n",
    "                        coressponding_auid = author_dict.get(ca_name, None)\n",
    "\n",
    "                        subject_areas_list = safe_get(data, ['abstracts-retrieval-response', 'subject-areas', 'subject-area'], None)\n",
    "                        subject_areas_id = [subject_area.get('@code', None) for subject_area in subject_areas_list if isinstance(subject_area, dict)] if subject_areas_list else None\n",
    "                        \n",
    "                        authkeywords = safe_get(data, ['abstracts-retrieval-response', 'authkeywords'], None)\n",
    "                        keywords = None\n",
    "                        if authkeywords and 'author-keyword' in authkeywords:\n",
    "                            authkeyword = authkeywords.get('author-keyword', None)\n",
    "                            if(isinstance(authkeyword, dict)):\n",
    "                                keywords = re.sub(r'(?<=[\\s])([A-Z])', r' \\1', authkeyword.get('$', None)).split('  ')\n",
    "                            else:\n",
    "                                keywords = [k['$'] for k in authkeyword if isinstance(k, dict)]                            \n",
    "                        keywords = check_slice_or_single(keywords)\n",
    "                        \n",
    "                        idxterms_data = safe_get(data, ['abstracts-retrieval-response', 'idxterms'], None)\n",
    "                        idxterms = handleidx(idxterms_data)\n",
    "                        \n",
    "                        classification_list = safe_get(data, ['abstracts-retrieval-response', 'item', 'bibrecord', 'head', 'enhancement', 'classificationgroup', 'classifications'], None)\n",
    "                        classification_code = get_classification_codes(classification_list)\n",
    "                        classification_code = check_slice_or_single(classification_code)\n",
    "                        \n",
    "                        writer.writerow({\n",
    "                            'pid': filename,\n",
    "                            'corresponding_author': coressponding_auid,\n",
    "                            'title': title,\n",
    "                            'pub_date': pub_date,\n",
    "                            'abstract': abstract,\n",
    "                            'language': language,\n",
    "                            'ref_count': ref_count,\n",
    "                            'citedby_count': citedby_count,\n",
    "                            'author_id': author_id,\n",
    "                            'subject_areas_id': subject_areas_id,\n",
    "                            'keywords': keywords,\n",
    "                            'idxterms': idxterms,\n",
    "                            'classification_code': classification_code\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Phuree---#\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from pprint import pprint\n",
    "geolocator = Nominatim(user_agent=\"isdjuiodfgdfjnjf847hn5\")\n",
    "\n",
    "data_dir = './Sample_data'\n",
    "output_file = '../CSVs/papers-mock.csv'\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for root, _, files in os.walk(data_dir):\n",
    "    for filename in files:\n",
    "        if cnt == 50: break\n",
    "        cnt+=1\n",
    "        if filename.startswith('20'):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                    \n",
    "                    # Extract organization (institution) information\n",
    "                    org_list = safe_get(data, ['abstracts-retrieval-response', 'item', 'bibrecord', 'head', 'correspondence','affiliation','organization'], None)\n",
    "                    organization = None\n",
    "                    if isinstance(org_list, list):\n",
    "                        organization = org_list[-1]['$'] if org_list else None\n",
    "                    elif isinstance(org_list, dict):\n",
    "                        organization = org_list.get('$', None)\n",
    "\n",
    "                    # city and cocity\n",
    "                    city_file = '../CSVs/city1.csv'\n",
    "                    #! Create new city.csv if it doesn't exist\n",
    "                    if not os.path.exists(city_file):\n",
    "                        city_df = pd.DataFrame(columns=['city_id', 'city', 'country', 'citation_sum', 'p_count','lat','lon'])\n",
    "                        city_dict = {}\n",
    "                        # Add a mock row\n",
    "                        mock_row = {\n",
    "                            'city_id': 1,\n",
    "                            'city': 'Mock City eiei',\n",
    "                            'country': 'Mock Country eiei',\n",
    "                            'citation_sum': 0,\n",
    "                            'p_count': 0,\n",
    "                            'lat': 0,\n",
    "                            'lon': 0\n",
    "                        }\n",
    "                        city_df.loc[-1] = mock_row\n",
    "                    else:\n",
    "                        city_df = pd.read_csv(city_file)\n",
    "\n",
    "                    city_dict = {}\n",
    "                    if city_df.shape[0] != 0:\n",
    "                        city_dict = {row['city']: row['city_id'] for _, row in city_df.iterrows()}\n",
    "\n",
    "                    citedby_count = safe_get(data, ['abstracts-retrieval-response','coredata','citedby-count'], None)\n",
    "                    citedby_count = int(citedby_count) if citedby_count else 0\n",
    "                    # print(\"count\",citedby_count)\n",
    "                    # set (city, country)\n",
    "                    city_country_set = set()\n",
    "                    \n",
    "                    affiliations = safe_get(data, ['abstracts-retrieval-response', 'affiliation'], None)\n",
    "                    # always return list or None\n",
    "                    affiliation_list = check_slice_or_single(affiliations) \n",
    "            \n",
    "                    for affiliation in affiliation_list:\n",
    "                        city = affiliation.get('affiliation-city', None)\n",
    "                        country = affiliation.get('affiliation-country', None)\n",
    "                        # print(city, country)\n",
    "                        if city and country:\n",
    "                            city_country_set.add((city, country))\n",
    "\n",
    "                    # Handle I. Single City, II. Multiple Cities\n",
    "                    if len(city_country_set) == 1:\n",
    "                        #! Case I: Single City\n",
    "                        city, country = list(city_country_set)[0]\n",
    "                        \n",
    "                        if city in city_dict:\n",
    "                            city_id = city_dict[city] \n",
    "                            city_df.loc[city_df['city_id'] == city_id, 'citation_sum'] += int(citedby_count)\n",
    "                            city_df.loc[city_df['city_id'] == city_id, 'p_count'] += 1\n",
    "                        else:\n",
    "                            city_id = len(city_dict) + 1\n",
    "                            city_dict[city] = city_id\n",
    "                            #geolocation \n",
    "                            # geo = geolocator.geocode(f\"{city}, {country}\")\n",
    "                            lat, lon = None, None\n",
    "                            # if geo:\n",
    "                            #     lat, lon = geo.latitude, geo.longitude\n",
    "                                \n",
    "                            new_row = pd.DataFrame([{\n",
    "                                'city_id': city_id,\n",
    "                                'city': city,\n",
    "                                'country': country,\n",
    "                                'citation_sum': int(citedby_count),\n",
    "                                'p_count': 1,\n",
    "                                'lat': lat,\n",
    "                                'lon': lon\n",
    "                            }])\n",
    "                            city_df = pd.concat([city_df, new_row], ignore_index=True)\n",
    "                    else:\n",
    "                        #! Case II: Multiple Cities\n",
    "                        for city, country in city_country_set:\n",
    "                            if city in city_dict:\n",
    "                                city_id = city_dict[city]\n",
    "                                city_df.loc[city_df['city_id'] == city_id, 'citation_sum'] += int(citedby_count)\n",
    "                                city_df.loc[city_df['city_id'] == city_id, 'p_count'] += 1\n",
    "                            else:\n",
    "                                city_id = len(city_dict) + 1\n",
    "                                city_dict[city] = city_id\n",
    "                                #geolocation \n",
    "                                # geo = geolocator.geocode(f\"{city}, {country}\")\n",
    "                                lat, lon = None, None\n",
    "                                # if geo:\n",
    "                                #     lat, lon = geo.latitude, geo.longitude\n",
    "                                new_row = pd.DataFrame([{\n",
    "                                    'city_id': city_id,\n",
    "                                    'city': city,\n",
    "                                    'country': country,\n",
    "                                    'citation_sum': int(citedby_count),\n",
    "                                    'p_count': 1,\n",
    "                                    'lat': lat,\n",
    "                                    'lon': lon\n",
    "                                }])\n",
    "                                city_df = pd.concat([city_df, new_row], ignore_index=True)\n",
    "\n",
    "                        # create cocity.csv and link the cities\n",
    "                        cocity_file = '../CSVs/cocity.csv'\n",
    "                        with open(cocity_file, 'a', newline='', encoding='utf-8') as cocity_csvfile:\n",
    "                            cocity_writer = csv.writer(cocity_csvfile)\n",
    "                            # Write header if file is empty\n",
    "                            if os.stat(cocity_file).st_size == 0:\n",
    "                                cocity_writer.writerow(['city_id1', 'city_id2', 'filename'])\n",
    "                            for city1, country1 in city_country_set:\n",
    "                                for city2, country2 in city_country_set:\n",
    "                                    if city1 != city2: # Avoid linking same city\n",
    "                                        city_id1 = city_dict[city1]\n",
    "                                        city_id2 = city_dict[city2]\n",
    "                                        cocity_writer.writerow([city_id1, city_id2, filename])\n",
    "\n",
    "\n",
    "                    city_df.to_csv(city_file, index=False)\n",
    "                     \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import wikipediaapi\n",
    "import world_bank_data as wb\n",
    "import pandas as pd\n",
    "from timezonefinder import TimezoneFinder\n",
    "import langcodes\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geoapiExeddsdsddsrcises111\")\n",
    "\n",
    "city = \"Bangkok\"\n",
    "country = \"Thailand\"\n",
    "\n",
    "data = geolocator.geocode(f\"{city}, {country}\")\n",
    "pprint(data.raw)\n",
    "\n",
    "#http://api.geonames.org/searchJSON?name=Providence&maxRows=1&username=phuree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching language data: Can't find any language named 'Mock Country eiei'\n",
      "City: Mock City eiei\n",
      "Country: Mock Country eiei\n",
      "Population: None\n",
      "GDP per Capita: None\n",
      "Latitude: 0.0\n",
      "Longitude: 0.0\n",
      "Time Zone: None\n",
      "Primary Language: None\n",
      "Safety Index: None\n",
      "\n",
      "Error fetching language data: Can't find any language named 'Viet Nam'\n",
      "City: Ho Chi Minh City\n",
      "Country: Viet Nam\n",
      "Population: 8993082\n",
      "GDP per Capita: None\n",
      "Latitude: 10.7763897\n",
      "Longitude: 106.7011391\n",
      "Time Zone: Asia/Ho_Chi_Minh\n",
      "Primary Language: None\n",
      "Safety Index: 48.52\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 73\u001b[0m\n\u001b[0;32m     71\u001b[0m time_zone \u001b[38;5;241m=\u001b[39m get_time_zone(lat, lng) \u001b[38;5;28;01mif\u001b[39;00m lat \u001b[38;5;129;01mand\u001b[39;00m lng \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     72\u001b[0m primary_language \u001b[38;5;241m=\u001b[39m get_primary_language(country)\n\u001b[1;32m---> 73\u001b[0m safety_index \u001b[38;5;241m=\u001b[39m \u001b[43mget_safety_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCountry: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 48\u001b[0m, in \u001b[0;36mget_safety_index\u001b[1;34m(city)\u001b[0m\n\u001b[0;32m     46\u001b[0m city_query \u001b[38;5;241m=\u001b[39m city\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.numbeo.com/crime/in/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 48\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mok:\n\u001b[0;32m     51\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1095\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:730\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001b[39;00m\n\u001b[0;32m    728\u001b[0m     server_hostname_rm_dot \u001b[38;5;241m=\u001b[39m server_hostname\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 730\u001b[0m     sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m        \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n\u001b[0;32m    750\u001b[0m \u001b[38;5;66;03m# If an error occurs during connection/handshake we may need to release\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;66;03m# our lock so another connection can probe the origin.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:909\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[0;32m    907\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 909\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\ssl_.py:469\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    465\u001b[0m         context\u001b[38;5;241m.\u001b[39mload_cert_chain(certfile, keyfile, key_password)\n\u001b[0;32m    467\u001b[0m context\u001b[38;5;241m.\u001b[39mset_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[1;32m--> 469\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\ssl_.py:513\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    510\u001b[0m     SSLTransport\u001b[38;5;241m.\u001b[39m_validate_ssl_context_for_tls_in_tls(ssl_context)\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:455\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    451\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1042\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   1040\u001b[0m                 \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1042\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1320\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[0;32m   1319\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from timezonefinder import TimezoneFinder\n",
    "import langcodes\n",
    "from bs4 import BeautifulSoup\n",
    "# Replace these with your own API keys\n",
    "GEONAMES_USERNAME = \"phuree\"\n",
    "\n",
    "def get_gdp_per_capita(country_code):\n",
    "    \"\"\"Fetch GDP per capita for a country from World Bank.\"\"\"\n",
    "    url = f\"http://api.worldbank.org/v2/country/{country_code}/indicator/NY.GDP.PCAP.CD?format=json\"\n",
    "    response = requests.get(url)\n",
    "    if response.ok and len(response.json()) > 1:\n",
    "        data = response.json()[1]\n",
    "        return data[0]['value'] if data else None\n",
    "    return None\n",
    "\n",
    "def get_time_zone(lat, lng):\n",
    "    try:\n",
    "        tf = TimezoneFinder()\n",
    "        return tf.timezone_at(lng=lng, lat=lat)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching time zone data: {e}\")\n",
    "\n",
    "def get_population(city, country):\n",
    "    \"\"\"Fetch latitude and longitude of a city using GeoNames.\"\"\"\n",
    "    url = f\"http://api.geonames.org/searchJSON?name={city}&maxRows=1&username={GEONAMES_USERNAME}\"\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        # print(data)\n",
    "        if data['geonames']:\n",
    "            return data['geonames'][0]['population']\n",
    "    return None\n",
    "\n",
    "def get_safety_index(city):\n",
    "    \"\"\"Scrape safety index from Numbeo website.\"\"\"\n",
    "    city_query = city.replace(\" \", \"-\")\n",
    "    url = f\"https://www.numbeo.com/crime/in/{city_query}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.ok:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # Find the safety index value in the page\n",
    "        table = soup.find(\"table\", {\"class\": \"table_indices\"})\n",
    "        if table:\n",
    "            safety_index = table.find_all(\"tr\")[2].find_all(\"td\")[1].text.strip()\n",
    "            return safety_index\n",
    "    return None\n",
    "\n",
    "df = pd.read_csv('../CSVs/city.csv')\n",
    "cnt = 0\n",
    "for index, row in df.iterrows():\n",
    "    if cnt == 6: break\n",
    "    cnt+=1\n",
    "    city = row['city']\n",
    "    country = row['country']\n",
    "    city_id = row['city_id']\n",
    "    lat = row['lat']\n",
    "    lng = row['lon']\n",
    "    population = get_population(city, country)\n",
    "    gdp_per_capita = get_gdp_per_capita(country)\n",
    "    time_zone = get_time_zone(lat, lng) if lat and lng else None\n",
    "    safety_index = get_safety_index(city)\n",
    "\n",
    "    print(f\"City: {city}\")\n",
    "    print(f\"Country: {country}\")\n",
    "    print(f\"Population: {population}\")\n",
    "    print(f\"GDP per Capita: {gdp_per_capita}\")\n",
    "    print(f\"Latitude: {lat}\")\n",
    "    print(f\"Longitude: {lng}\")\n",
    "    print(f\"Time Zone: {time_zone}\")\n",
    "    print(f\"Safety Index: {safety_index}\")\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
